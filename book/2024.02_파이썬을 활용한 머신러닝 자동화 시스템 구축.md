> ⚠️ 해당 글은 [파이썬을 활용한 머신러닝 자동화 시스템 구축(2022.08.31)](https://wikibook.co.kr/automl/)를 보고 정리한 내용 입니다.

> ⚠️ 해당 글은 2024년 2월 XX일부터 XX일까지 작성되었습니다.

<img src="../assets/book/2022_파이썬을 활용한 머신러닝 자동화 시스템 구축.jpg" width="200"/>


# 들어가며
## 머신러닝 자동화란?
- 사용자가 데이터 입력하면 데이터 정재, 특징 공학(feature engineering), 모델 선택, 하이퍼파라미터 튜닝, 모델 학습 등 일련의 과정을 자동으로 수행하여 머신러닝 모델을 개발

<img src="../assets/book_2023_파이썬을 활용한 머신러닝 자동화 시스템 구축/book_2023_머신러닝 자동화_01.jpg" width="600"/>

<em>AutoML의 목표(출처: AutoML 인 액션, 한빛미디어 2023)</em>

### 머신러닝 자동화 시스템 도입에 따른 효과
- 데이터 사이언티스트는 창의적인 분석에만 집중 -> 생산성 향상
- 데이터 분석 지식 없이도 머신러닝 모델 개발 가능

### 관련 패키지 및 시스템
- H2O AutoML: R, 파이썬, 웹 GUI 환경 지원 & 무료
- Google AutoML: 비정형 데이터 특화

### 머신러닝 자동화를 배워야 하는 이유
- 사용화된 머센러닝 자동화 시스템은 범용적인 목적으로 개발되었기 때문
- 자동화를 배우는 과정에서 실질적인 머신러닝 모델 개발 과정을 익힐 수 있음
  - 머신러닝 모델을 학습한다고 좋은 모델은 만드는 것은 아님
  - ex)) 어느 전처리 방법 사용?, 신경망이 decision tree 보다 좋은지?, 은닉층이 몇 개가 적절?

### 활용 데이터 소개
- 데이터 출처: KEEL
 
# [01부] 머신러닝 핵심 개념

##  1장: 머신러닝 모델 개발 프로세스
### 1.1 머신러닝 과제의 분류

### 지도 학습
- 데이터로 주어진 입력과 출력간 관계를 학습하여 새로운 입력에 대해 적절한 출력을 내는 머신러닝 방식

###  모델 학습 및 활용 과정
- 학습: 데이터 $D = \left\{ {\left( {{x^{(i)}},{y^{(i)}}} \right)|i = 1,2,...,n} \right\}$를 바탕으로 적절한 함수를 찾아가는 과정
  - $x^{(i)}=(x_1^{^{(i)}}, x_2^{^{(i)}},...,x_m^{^{(i)}})$: $i$번째 특징 벡터
  - $y^{(i)}$: $y$번째 라벨
- $(x^{(i)}, y^{(i)})$와 같이 특징 벡터와 라벨은 하나의 쌍을 이움 $\rightarrow$ 이러한 쌍을 sample or record or instance라 부름
  - 즉, $D$는 $n$개의 샘플과 $m$개의 특징으로 구성된 데이터
- **모델학습**은 손실함수가 최소화 되도록 모델의 파라미터(parameter)를 추정하는 작업
  - 파라미터: 모델의 예측값에 영향을 주는 변수를 의미
  - 손실함수(or 비용함수): 파라미터에 따른 예측 오파를 나타내는 함수
- 한 번에 최적의 파라미터를 찾을 수 없으므로, 여러 번의 시행착오(iteration)를 통해 최적의 파라미터를 찾음(못 찾을 때도 많음)
- 지도학습 모델 학습 및 활용 과정
  - `모델학습`: 데이터가 주어졌을 때, 비용함수 $L_\theta$를 최소화하는 파라미터 $\theta$인 $\hat{\theta}$를 추정하는 것
  - `추론`: 학습된 모델로 새로운 특정벡터 $x^{n+1}$에 대한 라벨을 $f(x^{n+1})|\hat{\theta}$로 예측하는 것
<img src="../assets/book_2023_파이썬을 활용한 머신러닝 자동화 시스템 구축/book_2023_머신러닝 자동화_02.png" width="600"/>
<em>출처: 파이썬을 활용한 머신러닝 자동화 시스템 구축, 한빛미디어 2022</em>

- 사용자가 한 일: 데이터를 준비하고 모델 $f$와 비용함수 $L$, 하이퍼파라미터를 선택 
> 한 데이터에 대해 적합한 모델, 하이퍼파라미터, 비용함수를 자동으로 산택할 수 있다면 기본적인 모델학습을 자동화할 수 있음

### 상태 공간(state space)과 지도 학습 과제의 분류
- 지도학습 과제는 라벨의 유향에 따라 분류(classification)와 회귀(regression)로 구분
  - 분류: 라벨이 범주형 변수인 지도학습 과제
  - 회귀: 라벨이 연속형 변수인 지도학습 과제
- 범주형, 연속형 변수는 상태공간의 크기에 따라 결정 $\rightarrow$ 유한, 무한 
  - 상태 공간(state space): 한 변수가 취할 수 있는 모든 값의 집합

### 일반화와 과적합
- 지도학습의 목표는 `우리가 관측하지 못한 새로운 데이터의 라벨을 잘 예측하는 것` -> **일반화** 능력
- 새로 입력될 데이터가 어떻게 생겼을지 모르지만, 현재 가지고 있는 데이터 분포와 비슷하리라 예상
- 데이터 분포를 적절히 반영한 모델 $f_2$가 더 좋은 모델
  - $f_1$: 현재 데이터 분포를 제대로 반영하지 못함
  - $f_3$: 현재 데이터만 반영하고 있는 모델
<img src="../assets/book_2023_파이썬을 활용한 머신러닝 자동화 시스템 구축/book_2023_머신러닝 자동화_03.png" width="600"/>
<em>출처: 파이썬을 활용한 머신러닝 자동화 시스템 구축, 한빛미디어 2022</em>

- 학습 데이터 대비 모델이 복잡할 수록 과적합 가능성이, 단순할수록 과소적합 가능성이 커짐

### 데이터 분할: (1) 학습 데이터와 평가 데이터
- 학습에 사용한 데이터를 그대로 평가 모델에 사용하면 모델을 더 좋게 평가 -> 학습용과 평가용으로 분할 필요
<img src="../assets/book_2023_파이썬을 활용한 머신러닝 자동화 시스템 구축/book_2023_머신러닝 자동화_04.png" width="600"/>
<em>출처: 파이썬을 활용한 머신러닝 자동화 시스템 구축, 한빛미디어 2022</em>

- 통상 6:4 or 7:3 정도 바율로 분할
- 평가 데이터는 관측하지 않았다고 간주 -> 객관적인 모델 평가를 위해 평가 데이터는 탐색, 전처리, 파라미터 추정 등 모델을 학습하는 전 과정에서 활용하면 안됨

### 데이터 분할: (2) k-겹 교차 검증
- 위 방식의 문제점
  - 평가 데이터 비활용 -> 학습에 사용하는 샘플이 많을수록 일반화 능력이 뛰어난 모델을 학습할 가능성이 크나 활용하지 못해서
  - 모델이 평가 데이터에 과적합될 위험이 있음 -> 평가 데이터에만 적합한 모델을 최종으로 선정
- **k-겹 교차 검증(k-fold cross validation)**: 객관적인 평가가 필요할 때
  - 데이터를 서로 겹치지 않은 k개의 작은 데이터인 폴드로 분할한뒤, 각각의 폴드를 평가 데이터로 사용하고 나머지 폴드의 합집합을 학습 데이터로 사용하는 방법
  - 아래 그림처럼 Fold 1을 빼고, Fold 2-5를 학습한 결과 1, Fold 2를 빼고 Fold 1, 3-5를 학습한 결과 2.. 이런방식으로 나온 결과 1-5를 종합(ex. 평균, 최소, 최대)하여 평가  
<img src="../assets/book_2023_파이썬을 활용한 머신러닝 자동화 시스템 구축/book_2023_머신러닝 자동화_05.png" width="600"/>
<em>출처: scikit-learn.org</em>

### 비지도 학습

### 군집화
### 이상 탐지


###요약
1.2 문제 정의와 데이터 수집
###머신러닝 프로세스
###문제 정의
###데이터 수집
###요약
1.3 데이터 탐색 및 전처리
###기초 데이터 탐색
###결측치 처리
###범주형 변수 처리
###분포 확인
###클래스 불균형 문제
###특징 공학
###요약
1.4 모델 학습: 모델 선택 및 하이퍼파라미터 튜닝
###모델 선택
###하이퍼파라미터 튜닝
###요약
1.5 모델 평가
###분류 모델 평가
###회귀 모델 평가
###요약

▣ 02장: 파이썬을 이용한 머신러닝 모델 학습
2.1 데이터 준비
###데이터 불러오기
###데이터 확인하기
2.2 데이터 탐색 및 전처리
###사이킷런을 이용한 데이터 전처리
###결측 처리
###범주 및 서열형 변수 처리
###재샘플링
###특징 선택
###요약
2.3 모델 학습 및 평가
###모델 학습
###모델 평가
###요약
2.4 파이프라인과 모델 저장
###머신러닝 파이프라인
###피클 모듈
###요약

▣ 03장: 주요 지도 학습 모델
3.1 선형 모델
###선형 회귀
###로지스틱 회귀
###선형성을 고려한 특징 공학
###요약
3.2 k-최근접 이웃
###작동 과정 및 모델의 장단점
###주요 하이퍼파라미터
###스케일링과 특징 공학의 필요성
###사이킷런 실습
###요약
3.3 결정 나무
###모델 구조와 작동 과정
###모델 특성
###주요 하이퍼파라미터
###사이킷런 실습
###요약
3.4 신경망
###모델 구조와 작동 과정
###학습 과정과 주요 파라미터
###사이킷런 실습
###요약
3.5 앙상블 모델
###앙상블 종류
###결정 나무 기반의 앙상블 모델
###요약

[02부] 머신러닝 자동화를 위한 최적화 알고리즘

▣ 04장: 최적화 문제
4.1 최적화 모델
###최적화 모델의 구성
###최적화 모델 및 그래프 기반의 해법 예제
###머신러닝 자동화를 위한 최적화
###요약
4.2 다양한 해법
###최적화 문제의 해법 개요
###휴리스틱 해법
###초기화
###평가
###속도 계산
###위치 업데이트
###요약

▣ 05장: 그리드 서치와 랜덤 서치
5.1 그리드 서치
###개요
###구현 실습
###요약
5.2 랜덤 서치
###개요
###확률 변수 분포
###관련 함수
###요약

▣ 06장: 유전 알고리즘
6.1 이론
###개요
###유전자 표현
###선택 연산
###교차 연산
###돌연변이 연산
###주요 하이퍼파라미터
###요약
6.2 실습 (1) 특징 선택
###문제 정의
###유전 알고리즘 연산자 정의
###메인 함수
###요약
6.3 실습 (2) 외판원 순회 문제
###문제 정의
###유전 알고리즘 연산자 정의
###메인 함수
###요약

▣ 07장: 베이지안 최적화
7.1 이론
###블랙박스 최적화 문제
###베이지안 최적화 개요
###대체 모델
###획득 함수
###메인 함수
###요약

[03부] 머신러닝 자동화 시스템 구축

▣ 08장: 머신러닝 자동화를 위한 테크닉
8.1 속도 향상을 위한 테크닉
###조기 종료(early stopping)
###다중 충실도(multi-fidelity)
###확장성(scalability)
###요약
8.2 웜 스타트와 메타 학습
###메타 학습
###실습: 메타 학습을 이용한 하이퍼파라미터 튜닝의 웜 스타트
###요약
8.3 튜닝 범위 설정
###튜닝 범위 설정의 필요성 및 개요
###반복측정 분산분석을 이용한 주요 하이퍼파라미터 식별
###결정 나무를 이용한 하이퍼파라미터 범위 설정
###요약

▣ 09장: 머신러닝 자동화를 위한 파이썬 패키지
9.1 Auto-Sklearn
###이론적 배경
###패키지 실습
###요약
9.2 H2O AutoML
###이론적 배경
###실습
###요약

▣ 10장: 실전 시스템 구축
10.1 시스템 (1) MyAutoML1
###문제 정의
###클래스 설계
###시스템 구현 및 활용
10.2 시스템 (2) MyAutoML2
###클래스 설계
###실험을 통한 하이퍼파라미터 범위 설정
###랜덤 포레스트의 하이퍼파라미터 범위 설정
###XGBoost의 하이퍼파라미터 범위 설정
###LightGBM의 하이퍼파라미터 범위 설정
###시스템 구현 및 활용
10.3 시스템 (3) MyAutoML3
###문제 정의
###클래스 설계
###메타 모델 학습
###시스템 구현 및 활용

▣ 마치며