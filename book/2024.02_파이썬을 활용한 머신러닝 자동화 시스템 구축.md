> ⚠️ 해당 글은 [파이썬을 활용한 머신러닝 자동화 시스템 구축(2022.08.31)](https://wikibook.co.kr/automl/)를 보고 정리한 내용 입니다.

> ⚠️ 해당 글은 2024년 2월 XX일부터 XX일까지 작성되었습니다.

<img src="../assets/book/2022_파이썬을 활용한 머신러닝 자동화 시스템 구축.jpg" width="200"/>


# 들어가며
## 머신러닝 자동화란?
- 사용자가 데이터 입력하면 데이터 정재, 특징 공학(feature engineering), 모델 선택, 하이퍼파라미터 튜닝, 모델 학습 등 일련의 과정을 자동으로 수행하여 머신러닝 모델을 개발

<img src="../assets/book_2023_파이썬을 활용한 머신러닝 자동화 시스템 구축/book_2023_머신러닝 자동화_01.jpg" width="600"/>

<em>AutoML의 목표(출처: AutoML 인 액션, 한빛미디어 2023)</em>

### 머신러닝 자동화 시스템 도입에 따른 효과
- 데이터 사이언티스트는 창의적인 분석에만 집중 $\rightarrow$ 생산성 향상
- 데이터 분석 지식 없이도 머신러닝 모델 개발 가능

### 관련 패키지 및 시스템
- H2O AutoML: R, 파이썬, 웹 GUI 환경 지원 & 무료
- Google AutoML: 비정형 데이터 특화

### 머신러닝 자동화를 배워야 하는 이유
- 사용화된 머센러닝 자동화 시스템은 범용적인 목적으로 개발되었기 때문
- 자동화를 배우는 과정에서 실질적인 머신러닝 모델 개발 과정을 익힐 수 있음
  - 머신러닝 모델을 학습한다고 좋은 모델은 만드는 것은 아님
  - ex) 어느 전처리 방법 사용?, 신경망이 decision tree 보다 좋은지?, 은닉층이 몇 개가 적절?

### 활용 데이터 소개
- 데이터 출처: KEEL
 
# [01부] 머신러닝 핵심 개념

#  1장: 머신러닝 모델 개발 프로세스
## 1.1 머신러닝 과제의 분류

### 지도 학습
- 데이터로 주어진 입력과 출력간 관계를 학습하여 새로운 입력에 대해 적절한 출력을 내는 머신러닝 방식

###  모델 학습 및 활용 과정
- 학습: 데이터 $D = \{ ( {{x^{(i)}},{y^{(i)}}} )|i = 1,2,...,n \} $를 바탕으로 적절한 함수를 찾아가는 과정
  - $x^{(i)}=(x_1^{^{(i)}}, x_2^{^{(i)}},...,x_m^{^{(i)}})$: $i$번째 특징 벡터
  - $y^{(i)}$: $y$번째 라벨
- $(x^{(i)}, y^{(i)})$와 같이 특징 벡터와 라벨은 하나의 쌍을 이움 $\rightarrow$ 이러한 쌍을 sample or record or instance라 부름
  - 즉, $D$는 $n$개의 샘플과 $m$개의 특징으로 구성된 데이터
- **모델학습**은 손실함수가 최소화 되도록 모델의 파라미터(parameter)를 추정하는 작업
  - 파라미터: 모델의 예측값에 영향을 주는 변수를 의미
  - 손실함수(or 비용함수): 파라미터에 따른 예측 오파를 나타내는 함수
- 한 번에 최적의 파라미터를 찾을 수 없으므로, 여러 번의 시행착오(iteration)를 통해 최적의 파라미터를 찾음(못 찾을 때도 많음)
- 지도학습 모델 학습 및 활용 과정
  - `모델학습`: 데이터가 주어졌을 때, 비용함수 $L_\theta$를 최소화하는 파라미터 $\theta$인 $\hat{\theta}$를 추정하는 것
  - `추론`: 학습된 모델로 새로운 특정벡터 $x^{n+1}$에 대한 라벨을 $f(x^{n+1})|\hat{\theta}$로 예측하는 것
<img src="../assets/book_2023_파이썬을 활용한 머신러닝 자동화 시스템 구축/book_2023_머신러닝 자동화_02.png" width="600"/>
<em>출처: 파이썬을 활용한 머신러닝 자동화 시스템 구축, 한빛미디어 2022</em>
<br/>

- 사용자가 한 일: 데이터를 준비하고 모델 $f$와 비용함수 $L$, 하이퍼파라미터를 선택 
> 한 데이터에 대해 적합한 모델, 하이퍼파라미터, 비용함수를 자동으로 산택할 수 있다면 기본적인 모델학습을 자동화할 수 있음

### 상태 공간(state space)과 지도 학습 과제의 분류
- 지도학습 과제는 라벨의 유향에 따라 분류(classification)와 회귀(regression)로 구분
  - 분류: 라벨이 범주형 변수인 지도학습 과제
  - 회귀: 라벨이 연속형 변수인 지도학습 과제
  <img src="../assets/book_2023_파이썬을 활용한 머신러닝 자동화 시스템 구축/book_2023_머신러닝 자동화_09.png" width="500"/>
- 범주형, 연속형 변수는 상태공간의 크기에 따라 결정 $\rightarrow$ 유한, 무한 
  - 상태 공간(state space): 한 변수가 취할 수 있는 모든 값의 집합



### 일반화와 과적합
- 지도학습의 목표는 `우리가 관측하지 못한 새로운 데이터의 라벨을 잘 예측하는 것` $\rightarrow$ **일반화** 능력
- 새로 입력될 데이터가 어떻게 생겼을지 모르지만, 현재 가지고 있는 데이터 분포와 비슷하리라 예상
- 데이터 분포를 적절히 반영한 모델 $f_2$가 더 좋은 모델
  - $f_1$: 현재 데이터 분포를 제대로 반영하지 못함
  - $f_3$: 현재 데이터만 반영하고 있는 모델
<img src="../assets/book_2023_파이썬을 활용한 머신러닝 자동화 시스템 구축/book_2023_머신러닝 자동화_03.png" width="600"/>
<em>출처: 파이썬을 활용한 머신러닝 자동화 시스템 구축, 한빛미디어 2022</em>  
<br/>
- 학습 데이터 대비 모델이 복잡할 수록 과적합 가능성이, 단순할수록 과소적합 가능성이 커짐

### 데이터 분할: (1) 학습 데이터와 평가 데이터
- 학습에 사용한 데이터를 그대로 평가 모델에 사용하면 모델을 더 좋게 평가 $\rightarrow$ 학습용과 평가용으로 분할 필요
<img src="../assets/book_2023_파이썬을 활용한 머신러닝 자동화 시스템 구축/book_2023_머신러닝 자동화_04.png" width="600"/>
<em>출처: 파이썬을 활용한 머신러닝 자동화 시스템 구축, 한빛미디어 2022</em>
<br/>   
- 통상 6:4 or 7:3 정도 비율로 분할
- 평가 데이터는 관측하지 않았다고 간주 $\rightarrow$ 객관적인 모델 평가를 위해 평가 데이터는 탐색, 전처리, 파라미터 추정 등 모델을 학습하는 전 과정에서 활용하면 안됨

### 데이터 분할: (2) k-겹 교차 검증
- 위 방식의 문제점
  - 평가 데이터 비활용 $\rightarrow$ 학습에 사용하는 샘플이 많을수록 일반화 능력이 뛰어난 모델을 학습할 가능성이 크나 활용하지 못해서
  - 모델이 평가 데이터에 과적합될 위험이 있음 $\rightarrow$ 평가 데이터에만 적합한 모델을 최종으로 선정
- **k-겹 교차 검증(k-fold cross validation)**: 객관적인 평가가 필요할 때
  - 데이터를 서로 겹치지 않은 k개의 작은 데이터인 폴드로 분할한뒤, 각각의 폴드를 평가 데이터로 사용하고 나머지 폴드의 합집합을 학습 데이터로 사용하는 방법
  - 아래 그림처럼 Fold 1을 빼고, Fold 2-5를 학습한 결과 1, Fold 2를 빼고 Fold 1, 3-5를 학습한 결과 2.. 이런방식으로 나온 결과 1-5를 종합(ex. 평균, 최소, 최대)하여 평가  
<img src="../assets/book_2023_파이썬을 활용한 머신러닝 자동화 시스템 구축/book_2023_머신러닝 자동화_05.png" width="600"/>
<em>출처: scikit-learn.org</em>

### 비지도 학습
- 라벨이 주어지지 않으므로 객관적인 평가와 오차에 따른 피드백 불가
- 데이터에 숨겨진 특징이나 구조를 발견하는 데 주로 활용

### 군집화
- 유사한(거리가 가까운) 샘플을 하나의 그룹으로 묶고 유사하지 않은 샘플을 다른 그룹으로 묶는 비지도 학습 과제
  - 유사도/거리 척도 예: 유클리드 거리, 코사인 거리, 매칭 유사도
  - 군집화 알고리즘 예: K평균 군집화, 계층적 군집화
- 예시 1) 세 개의 클러스터를 가진 가상의 2D 데이터를 생성하고, K-평균 알고리즘을 사용하여 클러스터링을 수행
<img src="../assets/book_2023_파이썬을 활용한 머신러닝 자동화 시스템 구축/book_2023_머신러닝 자동화_06.png" width="500"/>
<br/>   
- 예시 2) 세 개의 클러스터를 가진 가상의 2D 데이터를 생성하고, 계층적 군집화를 수행
<img src="../assets/book_2023_파이썬을 활용한 머신러닝 자동화 시스템 구축/book_2023_머신러닝 자동화_07.png" width="500"/>

### 이상 탐지
- 데이터에서 이상한 샘플을 찾아내는 비지도 학습 과제 $\rightarrow$ 다른 샘플과 많이 다른 샘플을 찾아내는 것
<img src="../assets/book_2023_파이썬을 활용한 머신러닝 자동화 시스템 구축/book_2023_머신러닝 자동화_08.png" width="500"/>


## 1.2 문제 정의와 데이터 수집

### 머신러닝 프로세스
1. 문제정의
   - 목표를 정의하고 해결하려는 문제를 명확히 이해
   - 지도 학습인지, 비지도 학습인지, 강화 학습인지 결정하고, 분류, 회귀, 군집화 등의 작업을 선택
2. 데이터 수집
   - 모델을 학습시키기 위한 데이터를 수집
   - 데이터의 출처와 형식을 이해하고, 데이터 수집 과정에서 발생할 수 있는 문제를 고려
3. 데이터 탐색
   - 데이터의 구조를 파악하고 특성을 탐색
   - 시각화와 통계적 분석을 사용하여 데이터의 패턴을 이해
4. 데이터 전처리
   - 결측치나 이상치를 처리하고, 데이터를 정규화 또는 표준화
   - 범주형 데이터를 인코딩하고, 특성 선택 또는 추출을 수행
5. 모델링
   - 적절한 머신러닝 알고리즘을 선택하고, 모델을 학습
   - 하이퍼파라미터를 조정하여 최적의 모델을 찾기
6. 모델 평가
   - 학습된 모델을 테스트 데이터에 적용하여 성능을 평가
   - 정확도, 정밀도, 재현율 등의 지표를 사용하여 모델의 성능을 측정
7. 모델 적용
   - 만족스러운 성능을 보이는 모델을 적용하여 실전에서 사용
   - 모델의 예측 결과를 해석하고 활용하여 문제를 해결


<img src="../assets/book_2023_파이썬을 활용한 머신러닝 자동화 시스템 구축/book_2023_머신러닝 자동화_10.png" width="600"/>

<em>출처: https://m.blog.naver.com/dnjswns2280/221598803717</em>

### 문제 정의
- 과제 유형 정의
  1) 반드시 머신러닝을 사용해야 하는가? $\rightarrow$ 아니라면 ML사용 포기 
  2) 지금까지 하던 일을 자동화하는 것인가? $\rightarrow$ '예'라면 지도학습 과제
  3) 새로운 인사이트를 발견하는 것이 목표인가? $\rightarrow$ '예'라면 비지도학습, 통계 분석, 시각화 과제
  4) 전문가가 지금까지 하던 일을 도와주는 것이 목표인가? $\rightarrow$ '예'라면 지도학습 과제
  5) 시간만 지나면 정답을 알수 있는 과제인가? $\rightarrow$ '예'라면 시계열 지도학습 과제
  6) 지도학습 과제 같지만 실제 정답을 알기 어려운 과제인가? $\rightarrow$ '예'라면 이상탐지, 추천과 관련
<br/>

- 사용 데이터 정의: 특징과 라벨을 중심으로
  1) 데이터를 정말 수집할 수 있는가?
  2) 새로운 데이터의 라벨을 정말 알수 없는가? $\rightarrow$ 라벨을 예측하는 모델 생성 필요
  3) 특징이나 라벨이 구체적인가?
  4) 사용하고자 하는 특징이 샘플마다 차이가 있는가?
  5) 특징별 수집 주가가 같은가? 특징별 수집 주기가 다르다면 실제적인 모델 활용이 어려울 수 있음
### 분석 목표 및 계획 수립
- 분석 목표는 특정 수치가 아니라 방향이 되어야 함
  - ex) 정확도 95%이상인 모델 (X) $\rightarrow$ 가벼운 모델을 만들겠다. 설명력이 높은 모델을 만들겠다. 예측력이 높은 모델을 만들겠다. (O)

### 데이터 수집
- 데이터 수집 후 데이터의 문제를 확인하는 것이 중요
  - 수집한 데이터가 현실을 반영하는 지 
  - 해결하고자 하는 문제와 무관한 데이터를 수집하지 않았는지 확인
  - 특정한 상황이 데이터에 누락되지 않았는지 확인

## 1.3 데이터 탐색 및 전처리
### 기초 데이터 탐색
- 데이터 정합성 검토: 데이터의 품질과 정확성을 확인하고, 데이터가 분석이나 모델링 작업에 적합한지 평가하는 과정

| 검토 요소   | 설명                                                             |
|------------|------------------------------------------------------------------|
| 결측치     | 데이터셋 내에 누락된 값이 있는지 확인하고 처리 방법 결정 (예: 삭제, 대체 등) |
| 이상치     | 데이터셋에서 통계적으로 벗어난 값 식별 및 처리                        |
| 일관성     | 데이터가 일관된 형식과 기준을 따르는지 검토 (예: 날짜 형식, 범주형 레이블 등) |
| 중복 데이터 | 동일한 정보를 가진 중복된 레코드 식별 및 제거                        |
| 데이터 유효성 | 데이터가 정의된 규칙이나 제약 조건을 충족하는지 검토 (예: 데이터 필드의 값 범위 등) |

- 데이터 크기: 사용할 데이터의 양과 그 데이터가 모델 훈련에 적합한지를 평가하는 과정

| 검토 요소             | 설명 |
|------------------|----------------------------------------------------------------------------------------------------------------------------------------|
| 충분한 양의 데이터 | 모델, 특히 딥러닝 모델은 충분한 양의 데이터를 필요로 함. 데이터가 부족하면 과소적합의 위험이 있음 |
| 데이터 균형         | 각 클래스의 데이터가 균형을 이루어 모델이 특정 클래스에 편향되지 않도록 함 |
| 다양성             | 데이터가 다양한 시나리오와 조건을 포괄해야 모델이 더 일반화된 학습을 할 수 있음 |
| 차원의 저주         | 데이터의 특성(차원)이 많을수록 필요한 데이터 양이 기하급수적으로 증가함 |
| 메모리 및 계산 리소스 | 매우 큰 데이터 세트는 모델 훈련 시간을 길게 하고, 더 많은 컴퓨팅 파워를 요구할 수 있음 |

- 특징의 유형 확인: 데이터 세트 내의 각 특징(또는 변수)이 어떤 유형에 속하는지를 식별하고 분석하는 과정
  - 특징의 유형에 따라 특징이 차지하는 공간의 크기와 전처리하는 방법이 다름

| 특징 유형              | 하위 유형                                  | 예시                               |
|----------------------|-------------------------------------------|------------------------------------|
| 수치형 (Numerical)   | 연속형 (Continuous) / 이산형 (Discrete)     | 키, 몸무게, 온도 / 사람의 수, 제품의 결함 개수 |
| 범주형 (Categorical) | 명목형 (Nominal) / 순서형 (Ordinal)         | 성별, 국적, 색상 / 교육 수준, 평가 등급       |
| 시간적 (Temporal)    | -                                         | 거래 시간, 제조 날짜                |


### 결측치 처리
- 결측치의 종류와 예

| 결측치의 종류   | 설명     | 예시      |
|--|-----|------|
| MCAR (완전 무작위)    | 데이터가 완전히 무작위로 누락되는 경우로, 누락된 데이터가 다른 변수나 특성과 무관하게 발생            | 설문조사 중에 랜덤으로 몇몇 응답자들의 응답이 누락된 경우                                   |
| MAR (랜덤)            | 누락된 데이터가 다른 변수의 값에 의존하여 발생하는 경우이며, 누락된 변수 자체와는 무관하게 다른 변수에 의존 | 소득 데이터에서 여성들의 소득이 랜덤하게 누락된 경우                                    |
| MNAR (비랜덤)          | 누락된 데이터가 해당 변수 자체의 값과 관련이 있어 발생하는 경우로, 주로 변수의 값이 어려운 조건에서 발생  | 의료 조사에서 환자들 중 심각한 증상을 가진 환자들의 증상 기록이 누락된 경우                |

- 결측치를 처리하는 방법과 각 방법의 적용 상황

| 처리 방법            | 설명                                                     | 적용 상황                                      |
|---------------------|----------------------------------------------------------|-----------------------------------------------|
| 삭제 (Deletion)     | 결측치가 있는 행이나 열을 완전히 제거              | 결측치가 적고 데이터 손실이 크지 않을 때       |
| 대체 (Imputation)   | 평균, 중앙값, 최빈값 등을 사용하여 결측치를 대체  | 결측치가 많지 않고, 대체 값이 데이터 분포를 크게 왜곡하지 않을 때 |
| 예측 모델 사용      | 머신러닝 알고리즘을 사용하여 결측값을 예측하고 대체 | 결측치가 많고, 다른 변수들로부터 결측치를 추정할 수 있을 때 |
| 표시 (Indicator) 추가 | 결측치가 있는 데이터에 대해 별도의 표시(예: 0/1 플래그)를 추가하여 모델이 결측치의 존재를 인식하도록 함 | 결측치 자체가 정보를 포함하고 있을 때 (예: 결측이 특정 상황을 의미할 때) |

- 결측치 추정 방법

| 추정 방법                              | 설명                                                                 | 적용 상황                                                     |
|---------------------------------------|----------------------------------------------------------------------|--------------------------------------------------------------|
| 단순 대체 (Simple Imputation)         | 평균, 중앙값, 최빈값 등을 사용하여 결측치를 단순하게 대체      | 결측치 처리가 간단하고 빠르게 필요할 때                       |
| 다중 대체 (Multiple Imputation)       | 여러 번의 대체를 통해 결측치를 추정하고, 각 대체 결과를 종합하여 최종 추정값을 결정 | 결측치가 데이터의 불확실성을 반영해야 하고, 단일 추정치보다 더 정확한 추정이 필요할 때 |
| K-최근접 이웃 (K-NN)                  | 결측치가 있는 데이터 포인트와 가장 가까운 K개의 이웃 데이터 포인트를 기반으로 결측치를 추정 | 데이터가 충분하고 결측치 주변의 이웃 데이터가 유사한 패턴을 보일 때 |
| 회귀 대체 (Regression Imputation)     | 결측치가 있는 변수와 다른 변수 간의 관계를 사용하여 결측치를 회귀 분석을 통해 추정 | 결측치와 다른 변수 사이에 선형적 또는 비선형적 관계가 있을 때 |
| 기계 학습 방법 (Machine Learning Methods) | 결정 트리, 랜덤 포레스트, 그래디언트 부스팅 등과 같은 기계 학습 알고리즘을 사용하여 결측치를 추정 | 복잡한 데이터 구조에서 결측치를 추정할 때, 특히 다른 변수들 사이의 복잡한 상호작용을 모델링할 수 있을 때 |
|보간법 (Interpolation)	| 시계열 데이터 등에서 결측치 앞뒤의 값들을 사용하여 결측치를 선형적으로 또는 다른 방법으로 추정 |	시계열 데이터에서 연속적인 값들 사이에 결측치가 존재할 때 적합 |


### 범주형 변수 처리

- 범주형 변수를 처리하는 방법과 각 방법의 적용 상황

| 처리 방법                      | 설명                                                                 | 적용 상황                                                   |
|-------------------------------|----------------------------------------------------------------------|------------------------------------------------------------|
| 라벨 인코딩 (Label Encoding)   | 범주형 변수의 각 카테고리를 고유한 정수로 매핑                | 순서형 데이터 처리 시 또는 트리 기반 모델 사용 시 유용      |
| 원-핫 인코딩 (One-Hot Encoding) | 범주형 변수의 각 카테고리를 새로운 열로 변환하고, 각 열에 대해 해당 카테고리에 속하면 1, 아니면 0으로 표시 | 모델이 범주형 변수의 순서를 고려하지 않을 때 유용          |
| 더미화 (Dummy Variable)         | 원-핫 인코딩과 유사하지만, 다중공선성을 방지하기 위해 한 카테고리를 기준으로 하여 n-1개의 열만 생성 | 선형 모델 같이 다중공선성이 문제가 될 수 있는 모델 사용 시 유용 |
| 임베딩 (Embedding)              | 고차원 범주형 데이터를 저차원으로 표현하기 위해 사용되며, 주로 딥러닝에서 사용 | 복잡한 범주형 데이터를 처리하고, 데이터의 내재된 구조를 학습할 필요가 있을 때 유용 |

### 분포 확인
- 데이터 분포를 확인하는 방법과 각 방법의 적용 상황

| 분포 확인 방법                        | 설명                                                                 | 적용 상황                                                  |
|-------------------------------------|----------------------------------------------------------------------|-----------------------------------------------------------|
| 기술 통계 (Descriptive Statistics)   | 평균, 중앙값, 최빈값, 표준편차 등 기초 통계량을 계산하여 데이터의 중심 경향성과 변동성을 파악 | 데이터의 기본적인 특성과 구조를 이해할 때                 |
| 시각화 (Visualization)              | 히스토그램, 박스플롯, 산점도 등을 사용하여 데이터의 분포와 이상치, 패턴을 시각적으로 확인 | 데이터의 분포, 이상치, 변수 간의 관계를 직관적으로 이해할 때 |
| 상관 분석 (Correlation Analysis)     | 변수 간의 상관계수를 계산하여 변수들 사이의 선형적 관계를 파악 | 변수 간의 연관성을 파악하고, 피처 선택 과정에서 참고할 때   |
| 클래스 불균형 확인 (Class Imbalance Check) | 각 클래스의 샘플 수를 계산하여 데이터셋 내의 클래스 비율을 확인하고, 불균형 문제를 파악 | 분류 문제에서 각 클래스가 공정하게 대표되었는지 확인하고, 필요한 경우 샘플링 기법 적용 시 |


### 클래스 불균형 문제
- 특정 클래스의 샘플 수가 다른 클래스에 비해 현저히 적은 경우를 의미 $\rightarrow$ 주로 분류 문제에서 발생
  - 예) 특정 질병의 발병 여부를 예측하는 모델에서 발병하지 않은 경우가 대다수이고 발병한 경우가 상대적으로 적은 경우
<br/>

- 클래스 불균형 문제의 주요 도전과제
  1) 모델 편향(Bias): 모델이 다수 클래스에 민감하게 학습되어, 소수 클래스를 정확하게 예측하지 못할 수 있음
  2) 정확도의 한계: 정확도는 샘플 수가 많은 클래스에 높게 나타날 수 있으므로, 모델의 성능을 올바르게 평가하기 어려울 수 있음
  3) 과적합(Overfitting): 소수 클래스에 대한 샘플이 적기 때문에 모델이 해당 클래스에 대해 과도하게 학습되어 새로운 데이터에 일반화하기 어려울 수 있음
  4) 평가 지표 선택: 정확도 외에도 더 적절한 평가 지표(정밀도, 재현율, F1 스코어 등)를 선택하여 모델의 성능을 평가해야 함
<br/>

- 클래스 불균형 문제 해결 방안
  1) 재샘플링: 소수 클래스의 샘플을 오버샘플링하거나 다수 클래스의 샘플을 언더샘플링하여 클래스 간의 균형을 맞추는 방법
  2) 합성 샘플 생성: SMOTE(Synthetic Minority Over-sampling Technique)와 같은 방법을 사용하여 소수 클래스의 샘플을 합성하여 추가함으로써 균형을 맞춤
  3) 비용 민감 모델(Cost-sensitive Model): 소수 클래스의 오류에 더 큰 비용을 할당하여 모델이 이를 더 중요하게 처리하도록 함
  4) 적절한 평가 지표 사용: 정밀도(Precision), 재현율(Recall), F1 스코어와 같은 평가 지표를 사용하여 모델의 성능을 보다 정확하게 평가함

### 특징 공학
- 특징 공학의 주요 분류와 각 분류의 설명, 적용 예

| 특징 공학 유형                   | 설명                                                                                          | 적용 예                                           |
|-------------------------------|-----------------------------------------------------------------------------------------------|---------------------------------------------------|
| 특징 생성 (Feature Creation)   | 기존 데이터로부터 새로운 특징을 생성하여 데이터의 정보를 확장하는 것. 예를 들어, 날짜에서 요일을 추출하거나, 두 변수의 비율을 새로운 변수로 만드는 것 등이 있음 | 날짜 데이터로부터 요일 변수 생성, 텍스트 데이터에서 키워드 추출 |
| 특징 추출 (Feature Extraction) | 데이터로부터 유용한 정보를 추출하여 차원을 축소하는 과정. 예를 들어, PCA, t-SNE와 같은 방법을 사용하여 고차원 데이터를 저차원으로 변환 | 이미지 데이터에서 주요 특성 추출, 텍스트 데이터의 차원 축소 |
| 특징 선택 (Feature Selection)  | 데이터셋에서 가장 유용한 특징을 선택하여 모델의 성능을 최적화하는 것. 이는 불필요한, 노이즈를 일으키는 변수를 제거하고, 계산 비용을 줄이며, 모델의 해석을 용이하게 함 | 변수 중요도에 따른 선택, 상관 관계가 높은 변수 제거 |

- 특징 선택 방법에 대한 간략한 설명과 예시

| 특징 선택 방법  | 설명    | 예시    |
|-----|-----------|----|
| **필터링 (Filter)**   | 특징 간의 통계적인 속성이나 상관관계를 기반으로 특징을 선택합니다. 모델과는 독립적으로 적용 | 상관관계가 낮은 특징 제거, 분산이 낮은 특징 제거 등        |
| **래퍼 (Wrapper)**    | 실제 모델의 성능을 측정하여 특징을 선택합니다. 모델에 따라 여러 번 학습되기 때문에 계산 비용이 높을 수 있음 | 전진 선택법(Forward Selection), 후진 제거법(Backward Elimination) 등   |
| **임베디드 (Embedded)** | 모델 자체의 학습 과정에서 특징 선택이 이루어짐. 학습 도중에 특징의 중요도를 평가하여 선택   | L1 정규화(라쏘 회귀), 트리 기반 모델의 특징 중요도를 기반으로 한 선택 등 |


## 1.4 모델 학습: 모델 선택 및 하이퍼파라미터 튜닝

### 모델 선택
- 데이터 크기, 과제 유형, 특징 유형 등을 줬을 때 가장 좋을 것이라 예상되는 모델의 유형을 고르는 문제 $\rightarrow$ 데이터 사이언티스트가 해결해야 하는 가정 어려운 문제
  - 모델 유형이 많은데 어느 모델이 가장 적합할지 분석적으로 판단할 수 없기 때문
- 데이터 크기 및 밀도에 적합한 복잡도의 모델을 선택
- 데이터 공간이 클수록 복잡한 모델이 필요
- 데이터 공간이 넓고 샘플 개수가 적을 때는 단순한 모델 사용 -> 과적합 가능성 때문

### 하이퍼파라미터 튜닝
- 사용자가 직접 설정하는 모델의 파라미터
- 선택이 아닌 **튜닝**: 선택할 수 있는 가짓수가 엄청많아 직관과 경험으로 선택하지 않고 여러 개를 비교하기 때문 
- 하이퍼파라미터 튜닝은 모델 선택과 함께 머신러닝 자동화의 핵심
  - 모든 지도학습 모델 개발에 비슷하게 적용 가능
  - 도메인 지식 크게 필요하지 않아 자동화 수월
  - 모델 성능에 매우 큰 영향을 까치기 때문
- 하이퍼파라미터의 종류

| 하이퍼파라미터 |설명   | 예시     |
|-----|--------|-----|
| 학습률 (Learning Rate)  | 모델이 학습하는 속도를 조절. 너무 높으면 학습이 불안정해질 수 있고, 너무 낮으면 학습이 느려질 수 있음     | 0.01, 0.001     |
| 배치 크기 (Batch Size)      | 한 번에 네트워크를 통과시키는 데이터 샘플의 수. 너무 크면 메모리 오버헤드가 발생할 수 있고, 너무 작으면 학습이 불안정해질 수 있음 | 32, 64, 128     |
| 에포크 수 (Number of Epochs)  | 전체 학습 데이터셋이 네트워크를 통과하는 횟수. 너무 많으면 오버피팅의 위험이 있음      | 10, 100, 1000  |
| 은닉층 수 (Number of Hidden Layers)           | 모델 내의 은닉층의 수. 층이 많을수록 모델이 복잡해지지만, 오버피팅의 위험이 있음                | 2, 3, 4        |
| 은닉층 뉴런 수 (Number of Neurons in Hidden Layer) | 각 은닉층에서의 뉴런(노드)의 수. 뉴런이 많을수록 모델의 학습 능력이 증가하지만, 계산 비용이 증가함      | 50, 100, 200   |
| 정규화 파라미터 (Regularization Parameter)    | 모델의 복잡도에 패널티를 부여하여 오버피팅을 방지하는 파라미터. L1, L2 정규화 등이 있음                | 0.01, 0.001    |

## 1.5 모델 평가

### 분류 모델 평가
- 혼동행렬 (Confusion Matrix): 실제 값과 모델이 예측한 값의 조합을 기반으로, 모델이 얼마나 잘 또는 못하는지를 보여줌
  1. **True Positive (TP)**: 모델이 양성(Positive)으로 예측하였고, 실제 값도 양성
  2. **True Negative (TN)**: 모델이 음성(Negative)으로 예측하였고, 실제 값도 음성
  3. **False Positive (FP)**: 모델이 양성으로 예측하였지만, 실제 값은 음성인 경우
  4. **False Negative (FN)**: 모델이 음성으로 예측하였지만, 실제 값은 양성인 경우

  |                  | 실제 양성 | 실제 음성 |
  |-----------------|---------|---------|
  | **예측 양성** | TP      | FP      |
  | **예측 음성** | FN      | TN      |


- 주요 평가 지표
  - **정확도(Accuracy)**: 전체 예측 중 올바른 예측의 비율 \((TP + TN) / (TP + TN + FP + FN)\)
  - **정밀도(Precision)**: 양성으로 예측된 것들 중 실제로 양성인 것의 비율 \(TP / (TP + FP)\)
  - **재현율(Recall)**: 실제 양성 중 모델이 양성으로 올바르게 예측한 비율 \(TP / (TP + FN)\)
  - **F1 점수(F1 Score)**: 정밀도와 재현율의 조화 평균 \(2 * (Precision * Recall) / (Precision + Recall)\)


### 회귀 모델 평가

회귀 모델의 성능을 평가하기 위한 지표는 모델이 예측한 값과 실제 값 사이의 차이를 기반으로 합니다. 여기서는 회귀 분석에서 널리 사용되는 주요 평가 지표들에 대해 설명합니다:

1. **평균 제곱 오차 (Mean Squared Error, MSE)**:
   - MSE는 실제 값과 예측 값의 차이의 제곱에 대한 평균
   - MSE는 오차의 크기를 과장하기 때문에, 큰 오차에 대해 더 큰 벌점을 부여
   - 공식: \(MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2\)
     - 여기서 \(y_i\)는 실제 값, \(\hat{y}_i\)는 예측 값, \(n\)은 샘플 수

2. **평균 절대 오차 (Mean Absolute Error, MAE)**:
   - MAE는 실제 값과 예측 값의 절대 차이의 평균
   - MAE는 MSE에 비해 이상치(outliers)의 영향을 덜 받음
   - 공식: \(MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|\)

3. **루트 평균 제곱 오차 (Root Mean Squared Error, RMSE)**:
   - RMSE는 MSE의 제곱근으로, MSE의 스케일 문제를 해결
   - RMSE는 실제 값과 예측 값 사이의 평균 제곱 오차의 루트
   - 공식: \(RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}\)

4. **평균 절대 백분율 오차 (Mean Absolute Percentage Error, MAPE)**:
   - MAPE는 실제 값에 대한 예측 값의 절대 오차의 백분율 평균
   - 이 지표는 오차의 상대적 크기를 백분율로 표현하므로, 다른 스케일의 데이터셋 간 비교에 유용
   - 하지만 실제 값이 0에 가까울 때 MAPE는 매우 커질 수 있어, 이러한 경우에는 주의해서 사용.
   - 공식: \(MAPE = \frac{100\%}{n}\sum_{i=1}^{n}\left|\frac{y_i - \hat{y}_i}{y_i}\right|\)   

5. **결정 계수 (R-squared, \(R^2\))**:
   - \(R^2\)는 모델이 데이터의 변동성을 얼마나 잘 설명하는지를 나타내는 지표
   - 1에 가까울수록 모델이 데이터를 잘 설명한다고 할 수 있음
   - 공식: \(R^2 = 1 - \frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2}\)
     - 여기서 \(\bar{y}\)는 실제 값의 평균

6. **조정된 결정 계수 (Adjusted R-squared)**:
   - 조정된 \(R^2\)는 독립 변수의 수와 샘플 크기를 고려하여 \(R^2\)를 조정한 것
   - 이는 모델에 변수가 추가될 때마다 \(R^2\)가 자동으로 증가하는 문제를 해결합니다.


# 02장: 파이썬을 이용한 머신러닝 모델 학습
## 2.1 데이터 준비
###데이터 불러오기
###데이터 확인하기
2.2 데이터 탐색 및 전처리
###사이킷런을 이용한 데이터 전처리
###결측 처리
###범주 및 서열형 변수 처리
###재샘플링
###특징 선택
###요약
2.3 모델 학습 및 평가
###모델 학습
###모델 평가
###요약
2.4 파이프라인과 모델 저장
###머신러닝 파이프라인
###피클 모듈
###요약

▣ 03장: 주요 지도 학습 모델
3.1 선형 모델
###선형 회귀
###로지스틱 회귀
###선형성을 고려한 특징 공학
###요약
3.2 k-최근접 이웃
###작동 과정 및 모델의 장단점
###주요 하이퍼파라미터
###스케일링과 특징 공학의 필요성
###사이킷런 실습
###요약
3.3 결정 나무
###모델 구조와 작동 과정
###모델 특성
###주요 하이퍼파라미터
###사이킷런 실습
###요약
3.4 신경망
###모델 구조와 작동 과정
###학습 과정과 주요 파라미터
###사이킷런 실습
###요약
3.5 앙상블 모델
###앙상블 종류
###결정 나무 기반의 앙상블 모델
###요약

[02부] 머신러닝 자동화를 위한 최적화 알고리즘

▣ 04장: 최적화 문제
4.1 최적화 모델
###최적화 모델의 구성
###최적화 모델 및 그래프 기반의 해법 예제
###머신러닝 자동화를 위한 최적화
###요약
4.2 다양한 해법
###최적화 문제의 해법 개요
###휴리스틱 해법
###초기화
###평가
###속도 계산
###위치 업데이트
###요약

▣ 05장: 그리드 서치와 랜덤 서치
5.1 그리드 서치
###개요
###구현 실습
###요약
5.2 랜덤 서치
###개요
###확률 변수 분포
###관련 함수
###요약

▣ 06장: 유전 알고리즘
6.1 이론
###개요
###유전자 표현
###선택 연산
###교차 연산
###돌연변이 연산
###주요 하이퍼파라미터
###요약
6.2 실습 (1) 특징 선택
###문제 정의
###유전 알고리즘 연산자 정의
###메인 함수
###요약
6.3 실습 (2) 외판원 순회 문제
###문제 정의
###유전 알고리즘 연산자 정의
###메인 함수
###요약

▣ 07장: 베이지안 최적화
7.1 이론
###블랙박스 최적화 문제
###베이지안 최적화 개요
###대체 모델
###획득 함수
###메인 함수
###요약

[03부] 머신러닝 자동화 시스템 구축

▣ 08장: 머신러닝 자동화를 위한 테크닉
8.1 속도 향상을 위한 테크닉
###조기 종료(early stopping)
###다중 충실도(multi-fidelity)
###확장성(scalability)
###요약
8.2 웜 스타트와 메타 학습
###메타 학습
###실습: 메타 학습을 이용한 하이퍼파라미터 튜닝의 웜 스타트
###요약
8.3 튜닝 범위 설정
###튜닝 범위 설정의 필요성 및 개요
###반복측정 분산분석을 이용한 주요 하이퍼파라미터 식별
###결정 나무를 이용한 하이퍼파라미터 범위 설정
###요약

▣ 09장: 머신러닝 자동화를 위한 파이썬 패키지
9.1 Auto-Sklearn
###이론적 배경
###패키지 실습
###요약
9.2 H2O AutoML
###이론적 배경
###실습
###요약

▣ 10장: 실전 시스템 구축
10.1 시스템 (1) MyAutoML1
###문제 정의
###클래스 설계
###시스템 구현 및 활용
10.2 시스템 (2) MyAutoML2
###클래스 설계
###실험을 통한 하이퍼파라미터 범위 설정
###랜덤 포레스트의 하이퍼파라미터 범위 설정
###XGBoost의 하이퍼파라미터 범위 설정
###LightGBM의 하이퍼파라미터 범위 설정
###시스템 구현 및 활용
10.3 시스템 (3) MyAutoML3
###문제 정의
###클래스 설계
###메타 모델 학습
###시스템 구현 및 활용

▣ 마치며